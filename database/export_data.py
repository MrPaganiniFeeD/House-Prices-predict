import sys
import os
import pandas as pd
import json
from sqlalchemy import create_engine, text

sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from database.connection import db_config

def export_training_data_smart(output_path='data/train_exported.csv'):
    """–£–º–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ —Ñ–∏—á–∏ –∏–∑ JSON"""
    
    print("–£–º–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    engine = create_engine(db_config.url)
    
    # –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å - –ø–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
    with engine.connect() as conn:
        # –ü–æ–ª—É—á–∞–µ–º –æ–¥–Ω—É –∑–∞–ø–∏—Å—å —á—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É JSON
        sample_result = conn.execute(text("SELECT features FROM training_data LIMIT 1"))
        sample_row = sample_result.fetchone()
        
        if sample_row:
            # –ü–∞—Ä—Å–∏–º JSON —á—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å –≤—Å–µ –∫–ª—é—á–∏ (—Ñ–∏—á–∏)
            sample_features = json.loads(sample_row[0]) if isinstance(sample_row[0], str) else sample_row[0]
            feature_keys = list(sample_features.keys())
            print(f"üìä –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(feature_keys)} —Ñ–∏—á–µ–π")
            print(f"üìã –ü–µ—Ä–≤—ã–µ 10 —Ñ–∏—á: {feature_keys[:10]}")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
        query = "SELECT id, target, features FROM training_data"
        df = pd.read_sql(query, conn)
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ–º JSON –≤ –∫–æ–ª–æ–Ω–∫–∏
    features_df = pd.json_normalize(df['features'].apply(lambda x: json.loads(x) if isinstance(x, str) else x))
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å target
    result_df = pd.concat([df[['id', 'target']], features_df], axis=1)
    result_df = result_df.rename(columns={'target': 'SalePrice'})
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    result_df.to_csv(output_path, index=False)
    
    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {output_path}")
    print(f"üìä –ó–∞–ø–∏—Å–µ–π: {len(result_df)}")
    print(f"üìà –ö–æ–ª–æ–Ω–æ–∫: {len(result_df.columns)}")
    
    return result_df

def export_test_data_smart(output_path='data/test_exported.csv'):
    """–£–º–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    print("–£–º–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    engine = create_engine(db_config.url)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
    query = "SELECT id, original_id, features FROM test_data"
    df = pd.read_sql(query, engine)
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ–º JSON
    features_df = pd.json_normalize(df['features'].apply(lambda x: json.loads(x) if isinstance(x, str) else x))
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º
    result_df = pd.concat([df[['id', 'original_id']], features_df], axis=1)
    result_df = result_df.rename(columns={'original_id': 'Id'})
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    result_df.to_csv(output_path, index=False)
    
    print(f"‚úÖ –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {output_path}")
    print(f"üìä –ó–∞–ø–∏—Å–µ–π: {len(result_df)}")
    
    return result_df

if __name__ == "__main__":
    train_df = export_training_data_smart()
    test_df = export_test_data_smart()
    
    print(f"\n–¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {train_df.shape}")
    print(f"–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ: {test_df.shape}")